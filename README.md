# ğŸ§  database_chatbot_agent

A FastAPI-based chatbot that converts natural language queries into SQL to retrieve insights from a Google BigQuery dataset and respond intelligently via OpenAI's GPT API.

---

## ğŸ“ File Structure

```
/project-root
â”‚
â”œâ”€â”€ main.py                      # FastAPI app entry point
â”œâ”€â”€ powerbi/                     # ğŸ’¡ (Optional) Power BI integration logic
â”‚   â”œâ”€â”€ auth.py                  # Handles Azure AD token fetching
â”‚   â””â”€â”€ query.py                 # Sends queries to Power BI API
â”œâ”€â”€ .env                         # Stores API keys and secrets (do not commit)
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ static/                      # Frontend HTML interface
```

---

## ğŸš€ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/database_chatbot_agent.git
cd database_chatbot_agent
```

---

### 2. Create Azure Web App
- Go to the [Azure portal](https://portal.azure.com/#home)
- Navigate to **App Services** â†’ **Create**
- Select:
  - **Operating System**: Linux  
  - **Runtime Stack**: Python 3.11
- Fill in the rest of the fields and create the app
- After creation, youâ€™ll see your app listed under App Services

---

### 3. Configure OpenAI
- [Create an OpenAI account](https://platform.openai.com/docs/overview)
- [Add API credits](https://platform.openai.com/settings/organization/billing/overview)  
  (see [pricing here](https://openai.com/api/pricing))
- Go to [API Keys](https://platform.openai.com/account/api-keys) and create a new secret key
- On your Azure app:
  - Go to **Settings â†’ Configuration â†’ Environment Variables**
  - Add:
    ```
    Name: OPENAI_API_KEY
    Value: <your-openai-secret-key>
    ```

---

### 4. Prepare Google BigQuery Dataset
- Go to [Google Cloud Console](https://console.cloud.google.com/welcome)
- Open **BigQuery** from the top search bar
- Click **+ Add Data** and upload or connect your dataset (CSV or public)

ğŸ“ Make sure to note your full table path:  
`project_id.dataset_name.table_name`

---

### 5. Configure BigQuery API and Credentials
- [Create a new GCP project](https://console.cloud.google.com/projectselector2/home/dashboard)
- [Enable the BigQuery API](https://console.cloud.google.com/apis/library/bigquery.googleapis.com)
- [Create a service account](https://console.cloud.google.com/iam-admin/serviceaccounts)
  - Assign roles:
    - `BigQuery Data Viewer`
    - `BigQuery Job User`
    - (Optional) `BigQuery Admin`
- Generate a **JSON key** file
- On Azure:
  - Go to **Settings â†’ Configuration**
  - Add a new variable:
    ```
    Name: GOOGLE_APPLICATION_CREDENTIALS_JSON
    Value: <paste the contents of the JSON file>
    ```

---

### 6. Deploy via GitHub Actions
- On GitHub:
  - Go to **Settings â†’ Actions â†’ General**
  - Set: **Allow all actions and reusable workflows**
- On Azure:
  - Go to your app â†’ **Deployment Center**
  - Source: `GitHub`
  - Select:
    - Organisation
    - Repository
    - Branch
  - Enable **Continuous Deployment**

ğŸ” This allows your FastAPI app to be rebuilt and deployed on each GitHub commit.

ğŸ“½ï¸ [Watch deployment tutorial](https://www.youtube.com/watch?v=Rp-TMHrwCn4)

---

### 7. Access Your Application
- Go to **App Service â†’ Overview**
- Click **Browse** or copy the **URL** field

---

### 8. Debugging Logs
- Azure Portal â†’ App â†’ **Logs** â†’ **Log stream**

---

## âœ… Checklist Before Deployment

- [ ] Update `.env` or Azure env variables for OpenAI and BigQuery
- [ ] Ensure your `requirements.txt` is up-to-date
- [ ] Confirm the full table path is in your GPT SQL generation prompt
- [ ] Static files (HTML UI) are located in the `/static` folder
- [ ] Test locally with:
  ```bash
  uvicorn main:app --reload
  ```

---
